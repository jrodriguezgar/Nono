# API Manager - DocumentaciÃ³n

MÃ³dulo profesional para gestiÃ³n integral de APIs con rate limiting, circuit breaker, reintentos y mÃ©tricas.

## ðŸ“‹ Ãndice

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [InstalaciÃ³n](#instalaciÃ³n)
- [MigraciÃ³n desde api_rate_limiter](#migraciÃ³n-desde-api_rate_limiter)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [API Manager](#api-manager)
- [Rate Limiting](#rate-limiting)
- [Circuit Breaker](#circuit-breaker)
- [PolÃ­ticas de Reintentos](#polÃ­ticas-de-reintentos)
- [MÃ©tricas](#mÃ©tricas)
- [Decoradores](#decoradores)
- [Presets de Proveedores](#presets-de-proveedores)
- [API Reference](#api-reference)

---

## âœ¨ CaracterÃ­sticas

### Rate Limiting
- **MÃºltiples lÃ­mites simultÃ¡neos**: RPM, RPD, TPM, TPD, RPS y lÃ­mites concurrentes
- **Algoritmos configurables**: Token Bucket, Sliding Window, Fixed Window
- **Presets para APIs de IA**: OpenAI, Gemini, Claude, Perplexity, DeepSeek, Ollama

### Circuit Breaker
- **PatrÃ³n Circuit Breaker**: Previene cascada de fallos
- **Estados**: Closed, Open, Half-Open
- **Auto-recuperaciÃ³n**: Prueba automÃ¡tica de recuperaciÃ³n

### Reintentos
- **Estrategias mÃºltiples**: Fixed, Linear, Exponential, Fibonacci
- **Jitter configurable**: Evita thundering herd
- **Excepciones configurables**: Define quÃ© errores reintentar

### GestiÃ³n de APIs
- **Registro centralizado**: Gestiona mÃºltiples APIs desde un solo punto
- **MÃ©tricas completas**: EstadÃ­sticas de uso, latencia, errores
- **Presets de configuraciÃ³n**: Configuraciones listas para proveedores conocidos

---

## ðŸ“¦ InstalaciÃ³n

El mÃ³dulo estÃ¡ en el directorio `connector/`. Importar directamente:

```python
from api_manager import (
    # API Manager
    APIManager,
    APIConfig,
    APIConfigPresets,
    
    # Rate Limiting (backward compatible)
    APIRateLimiter,
    RateLimitConfig,
    AIProviderPresets,
    create_limiter_for_provider,
    
    # Circuit Breaker
    CircuitBreaker,
    CircuitBreakerConfig,
    
    # Retry
    RetryConfig,
    RetryStrategy,
    
    # Decorators
    with_rate_limit,
    with_retry,
    with_circuit_breaker,
    with_managed_api,
)
```

---

## ðŸ”„ MigraciÃ³n desde api_rate_limiter

El nuevo mÃ³dulo `api_manager` es **100% compatible hacia atrÃ¡s** con `api_rate_limiter`. 
Simplemente cambia el import:

```python
# Antes
from api_rate_limiter import APIRateLimiter, RateLimitConfig

# Ahora
from api_manager import APIRateLimiter, RateLimitConfig
```

Todo el cÃ³digo existente seguirÃ¡ funcionando sin cambios.

---

## ðŸš€ Uso RÃ¡pido

### OpciÃ³n 1: API Manager (Recomendado)

```python
from api_manager import APIManager, APIConfigPresets

# Crear manager
manager = APIManager()

# Registrar APIs con presets
manager.register_provider("openai", api_key="sk-...")
manager.register_provider("gemini", api_key="AI...")

# Usar con context manager
with manager.acquire("openai", tokens=1000):
    response = call_openai_api()

# O versiÃ³n async
async with manager.async_acquire("gemini", tokens=500):
    response = await call_gemini_api()
```

### OpciÃ³n 2: Rate Limiter Standalone

```python
from api_manager import APIRateLimiter, RateLimitConfig

# Configurar lÃ­mites
config = RateLimitConfig(
    rpm=60,
    tpm=100000,
    concurrent_limit=5
)

limiter = APIRateLimiter(config)

# Usar antes de cada llamada
with limiter.acquire_context(tokens=500):
    response = make_api_call()
```

### OpciÃ³n 3: Usar Presets

```python
from api_manager import create_limiter_for_provider

# Crear limitador preconfigurado
limiter = create_limiter_for_provider("gemini")
```

---

## ðŸ¢ API Manager

El `APIManager` es el punto central para gestionar mÃºltiples APIs.

### Registro de APIs

```python
from api_manager import APIManager, APIConfig, RateLimitConfig

manager = APIManager()

# Registrar con configuraciÃ³n personalizada
config = APIConfig(
    base_url="https://api.example.com",
    api_key="your-key",
    rate_limit=RateLimitConfig(rpm=100, tpm=50000),
    timeout=30.0
)
manager.register_api("my-api", config)

# O usar presets para proveedores conocidos
manager.register_provider("openai", api_key="sk-...")
manager.register_provider("gemini", api_key="AI...")
```

### Uso con Context Manager

```python
# El context manager gestiona automÃ¡ticamente:
# - Rate limiting
# - Circuit breaker
# - MÃ©tricas
# - LiberaciÃ³n de recursos

with manager.acquire("openai", tokens=1000):
    response = call_api()
    # Si hay error, se registra automÃ¡ticamente

# VersiÃ³n async
async with manager.async_acquire("openai", tokens=1000):
    response = await async_call_api()
```

### Obtener EstadÃ­sticas

```python
# EstadÃ­sticas de una API
api = manager.get_api("openai")
stats = api.get_stats()
print(stats)

# EstadÃ­sticas de todas las APIs
all_stats = manager.get_all_stats()
```

---

## âš¡ Rate Limiting

### ConfiguraciÃ³n de LÃ­mites

```python
from api_manager import RateLimitConfig, RateLimitAlgorithm

config = RateLimitConfig(
    # LÃ­mites de solicitudes
    rpm=60,           # 60 solicitudes por minuto
    rpd=10000,        # 10,000 solicitudes por dÃ­a
    rps=1.0,          # 1 solicitud por segundo
    
    # LÃ­mites de tokens (para APIs de IA)
    tpm=100000,       # 100,000 tokens por minuto
    tpd=1000000,      # 1,000,000 tokens por dÃ­a
    
    # Concurrencia
    concurrent_limit=10,  # 10 solicitudes simultÃ¡neas
    
    # Algoritmo
    algorithm=RateLimitAlgorithm.TOKEN_BUCKET,
    burst_size=15,    # RÃ¡faga mÃ¡xima
    
    # Comportamiento
    max_wait_time=300.0,  # Esperar mÃ¡ximo 5 minutos
)
```

### Glosario de LÃ­mites

| AcrÃ³nimo | Nombre | DescripciÃ³n |
|----------|--------|-------------|
| **RPM** | Requests Per Minute | Solicitudes por minuto |
| **RPD** | Requests Per Day | Solicitudes por dÃ­a |
| **RPS** | Requests Per Second | Solicitudes por segundo |
| **TPM** | Tokens Per Minute | Tokens por minuto (APIs de IA) |
| **TPD** | Tokens Per Day | Tokens por dÃ­a |

### Algoritmos

| Algoritmo | DescripciÃ³n | Mejor Para |
|-----------|-------------|------------|
| `TOKEN_BUCKET` | RÃ¡fagas controladas | Uso general, APIs de IA |
| `SLIDING_WINDOW` | Conteo preciso | LÃ­mites estrictos |
| `FIXED_WINDOW` | Contador simple | Simplicidad, compatibilidad |

---

## ðŸ”Œ Circuit Breaker

Previene cascada de fallos cuando un servicio estÃ¡ degradado.

### ConfiguraciÃ³n

```python
from api_manager import CircuitBreakerConfig, CircuitBreaker

config = CircuitBreakerConfig(
    failure_threshold=5,      # Abrir despuÃ©s de 5 fallos
    success_threshold=3,      # Cerrar despuÃ©s de 3 Ã©xitos
    timeout=60.0,             # Intentar recovery despuÃ©s de 60s
    half_open_max_calls=3,    # MÃ¡x llamadas en half-open
)

breaker = CircuitBreaker(config)
```

### Estados

```
CLOSED â”€â”€(failures >= threshold)â”€â”€> OPEN
   ^                                   â”‚
   â”‚                              (timeout)
   â”‚                                   â–¼
   â””â”€â”€(successes >= threshold)â”€â”€ HALF_OPEN
```

- **CLOSED**: OperaciÃ³n normal
- **OPEN**: Rechaza todas las solicitudes
- **HALF_OPEN**: Permite pruebas limitadas

### Uso Manual

```python
if breaker.can_execute():
    try:
        result = call_api()
        breaker.record_success()
    except Exception as e:
        breaker.record_failure(e)
        raise
else:
    raise CircuitBreakerOpenError("Circuit is open")
```

---

## ðŸ” PolÃ­ticas de Reintentos

### ConfiguraciÃ³n

```python
from api_manager import RetryConfig, RetryStrategy

config = RetryConfig(
    strategy=RetryStrategy.EXPONENTIAL,
    max_retries=3,
    base_delay=1.0,       # 1 segundo base
    max_delay=60.0,       # MÃ¡ximo 60 segundos
    jitter=0.1,           # 10% de variaciÃ³n aleatoria
    retryable_exceptions=(ConnectionError, TimeoutError),
    retryable_status_codes=(429, 500, 502, 503, 504),
)
```

### Estrategias

| Estrategia | Delays (base=1s) | DescripciÃ³n |
|------------|------------------|-------------|
| `NONE` | - | Sin reintentos |
| `FIXED` | 1, 1, 1, ... | Delay constante |
| `LINEAR` | 1, 2, 3, ... | Incremento lineal |
| `EXPONENTIAL` | 1, 2, 4, 8, ... | Incremento exponencial |
| `FIBONACCI` | 1, 1, 2, 3, 5, ... | Secuencia Fibonacci |

---

## ðŸ“Š MÃ©tricas

### MÃ©tricas de API

```python
api = manager.get_api("openai")
stats = api.get_stats()

print(f"Total requests: {stats['metrics']['total_requests']}")
print(f"Success rate: {stats['metrics']['success_rate']:.2%}")
print(f"Avg latency: {stats['metrics']['average_latency_ms']:.2f}ms")
print(f"Total tokens: {stats['metrics']['total_tokens_used']}")
```

### MÃ©tricas de Rate Limiter

```python
limiter_stats = api.rate_limiter.get_stats()

for name, data in limiter_stats["limiters"].items():
    print(f"{name.upper()}:")
    print(f"  Acquired: {data.get('total_acquired', 0)}")
    print(f"  Denied: {data.get('total_denied', 0)}")
```

### MÃ©tricas de Circuit Breaker

```python
cb_stats = api.circuit_breaker.get_stats()

print(f"State: {cb_stats['state']}")
print(f"Failures: {cb_stats['failure_count']}")
print(f"Total calls: {cb_stats['total_calls']}")
```

---

## ðŸŽ¯ Decoradores

### @with_rate_limit

```python
from api_manager import with_rate_limit, set_default_limiter

limiter = create_limiter_for_provider("openai")
set_default_limiter(limiter)

@with_rate_limit(tokens=500)
def call_openai(prompt: str) -> str:
    return openai_client.generate(prompt)
```

### @with_retry

```python
from api_manager import with_retry, RetryConfig

@with_retry(RetryConfig(max_retries=3))
def unreliable_api_call():
    return requests.get("https://api.example.com/data")
```

### @with_circuit_breaker

```python
from api_manager import with_circuit_breaker, CircuitBreaker, CircuitBreakerConfig

breaker = CircuitBreaker(CircuitBreakerConfig(failure_threshold=5))

@with_circuit_breaker(breaker)
def protected_call():
    return external_service.call()
```

### @with_managed_api

```python
from api_manager import with_managed_api, get_default_manager

manager = get_default_manager()
manager.register_provider("openai", api_key="sk-...")

@with_managed_api(api_name="openai", tokens=500)
def call_openai(prompt: str) -> str:
    return openai_client.generate(prompt)
```

---

## ðŸ¤– Presets de Proveedores

### Rate Limit Presets

```python
from api_manager import AIProviderPresets

# Obtener configuraciÃ³n preconfigurada
config = AIProviderPresets.openai_gpt4()
config = AIProviderPresets.google_gemini()
config = AIProviderPresets.anthropic_claude()
config = AIProviderPresets.perplexity()
config = AIProviderPresets.deepseek()
config = AIProviderPresets.ollama_local()
```

### API Config Presets

```python
from api_manager import APIConfigPresets

# ConfiguraciÃ³n completa con rate limit, circuit breaker, retry
config = APIConfigPresets.openai(api_key="sk-...")
config = APIConfigPresets.gemini(api_key="AI...")
config = APIConfigPresets.anthropic(api_key="sk-ant-...")
config = APIConfigPresets.perplexity(api_key="pplx-...")
config = APIConfigPresets.deepseek(api_key="sk-...")
config = APIConfigPresets.ollama(base_url="http://localhost:11434")
```

### Tabla de LÃ­mites por Proveedor

| Proveedor | RPM | TPM | Concurrent |
|-----------|-----|-----|------------|
| OpenAI GPT-4 | 500 | 10,000 | 100 |
| OpenAI GPT-4 Turbo | 5,000 | 450,000 | 100 |
| OpenAI GPT-3.5 | 10,000 | 2,000,000 | 200 |
| Gemini Free | 60 | 1,000,000 | 10 |
| Gemini Pro | 1,000 | 4,000,000 | 100 |
| Claude | 50 | 100,000 | 10 |
| Perplexity | 60 | 100,000 | - |
| DeepSeek | 60 | 1,000,000 | - |
| Ollama | - | - | 2 |

---

## ðŸ“š API Reference

### Clases Principales

| Clase | DescripciÃ³n |
|-------|-------------|
| `APIManager` | Gestor central de APIs |
| `APIRateLimiter` | Rate limiter configurable |
| `CircuitBreaker` | ImplementaciÃ³n circuit breaker |
| `ManagedAPI` | API gestionada individual |
| `APIMetrics` | MÃ©tricas de una API |

### Configuraciones

| Clase | DescripciÃ³n |
|-------|-------------|
| `APIConfig` | ConfiguraciÃ³n completa de API |
| `RateLimitConfig` | ConfiguraciÃ³n de rate limiting |
| `CircuitBreakerConfig` | ConfiguraciÃ³n de circuit breaker |
| `RetryConfig` | ConfiguraciÃ³n de reintentos |

### Excepciones

| ExcepciÃ³n | DescripciÃ³n |
|-----------|-------------|
| `APIManagerError` | Base para errores del manager |
| `RateLimitExceededError` | Rate limit excedido |
| `CircuitBreakerOpenError` | Circuit breaker abierto |
| `RetryExhaustedError` | Reintentos agotados |
| `APINotRegisteredError` | API no registrada |

### Enumeraciones

| Enum | Valores |
|------|---------|
| `RateLimitAlgorithm` | TOKEN_BUCKET, SLIDING_WINDOW, FIXED_WINDOW |
| `CircuitBreakerState` | CLOSED, OPEN, HALF_OPEN |
| `RetryStrategy` | NONE, FIXED, LINEAR, EXPONENTIAL, FIBONACCI |
| `APIStatus` | HEALTHY, DEGRADED, UNHEALTHY, UNKNOWN |

---

## ðŸ“ Ejemplos Completos

### Ejemplo: Cliente de IA Robusto

```python
from api_manager import (
    APIManager,
    APIConfig,
    RateLimitConfig,
    RetryConfig,
    CircuitBreakerConfig,
    RetryStrategy
)

# ConfiguraciÃ³n robusta
config = APIConfig(
    base_url="https://api.openai.com/v1",
    api_key="sk-...",
    rate_limit=RateLimitConfig(
        rpm=100,
        tpm=150000,
        concurrent_limit=10
    ),
    retry=RetryConfig(
        strategy=RetryStrategy.EXPONENTIAL,
        max_retries=3,
        base_delay=1.0
    ),
    circuit_breaker=CircuitBreakerConfig(
        failure_threshold=5,
        timeout=60.0
    ),
    timeout=60.0
)

# Crear manager y registrar
manager = APIManager()
manager.register_api("openai", config)

# Usar
async def generate_text(prompt: str) -> str:
    async with manager.async_acquire("openai", tokens=len(prompt)//4 + 500):
        response = await openai_client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

# Ver estadÃ­sticas
print(manager.get_all_stats())
```

### Ejemplo: Procesamiento por Lotes

```python
from api_manager import APIManager
import asyncio

manager = APIManager()
manager.register_provider("gemini", api_key="AI...")

async def process_batch(items: list) -> list:
    results = []
    
    for item in items:
        tokens = len(item) // 4 + 200
        
        async with manager.async_acquire("gemini", tokens=tokens):
            result = await process_item(item)
            results.append(result)
    
    # Ver mÃ©tricas despuÃ©s del procesamiento
    stats = manager.get_api("gemini").get_stats()
    print(f"Processed: {stats['metrics']['total_requests']}")
    print(f"Success rate: {stats['metrics']['success_rate']:.2%}")
    
    return results
```

---

## Dependencies

| Package | Version | Description |
|---------|---------|-------------|
| `requests` | >= 2.28.0 | HTTP library for API calls |
| `asyncio` | built-in | Async support for Python |

---

## Contact

- **Author**: [DatamanEdge](https://github.com/DatamanEdge)
- **Email**: [jrodriguezga@outlook.com](mailto:jrodriguezga@outlook.com)
- **LinkedIn**: [Javier RodrÃ­guez](https://es.linkedin.com/in/javier-rodriguez-ga)

---

## License

MIT Â© 2026 DatamanEdge. See [LICENSE](../../LICENSE).
